# import streamlit as st
# import whisper
# import torch
# import warnings
# from pathlib import Path
# import tempfile
# import logging
# import os
# from typing import Optional, Tuple
# import time

# # è¨­ç½®ç’°å¢ƒè®Šæ•¸å’Œè­¦å‘Šæ§åˆ¶
# os.environ["PYTHONWARNINGS"] = "ignore::FutureWarning"
# os.environ["TORCH_ENABLE_CPU_FALLBACK"] = "1"
# warnings.filterwarnings("ignore", category=FutureWarning)
# warnings.filterwarnings("ignore", category=UserWarning)
# logging.getLogger("whisper").setLevel(logging.ERROR)

# class AudioConverter:
#     SUPPORTED_MODELS = {
#         "tiny": "æœ€å°æ¨¡å‹ - æœ€å¿«ä½†æº–ç¢ºåº¦è¼ƒä½",
#         "base": "åŸºç¤æ¨¡å‹ - å¹³è¡¡é€Ÿåº¦å’Œæº–ç¢ºåº¦",
#         "small": "å°å‹æ¨¡å‹ - è¼ƒå¥½çš„æº–ç¢ºåº¦",
#         "medium": "ä¸­å‹æ¨¡å‹ - é«˜æº–ç¢ºåº¦",
#         "large": "å¤§å‹æ¨¡å‹ - æœ€é«˜æº–ç¢ºåº¦ä½†è¼ƒæ…¢"
#     }
    
#     def __init__(self):
#         self.model = None
#         self.model_name = None
#         self.device = "cuda" if torch.cuda.is_available() else "cpu"
#         self.cache_dir = Path.home() / ".cache" / "whisper"
#         self.cache_dir.mkdir(parents=True, exist_ok=True)
    
#     def load_model(self, model_name: str) -> bool:
#         """è¼‰å…¥æ¨¡å‹ï¼Œå¦‚æœå·²è¼‰å…¥ç›¸åŒæ¨¡å‹å‰‡è·³é"""
#         try:
#             if self.model is None or self.model_name != model_name:
#                 with st.spinner(f"è¼‰å…¥ {model_name} æ¨¡å‹ä¸­..."):
#                     self.model = whisper.load_model(
#                         model_name,
#                         device=self.device,
#                         download_root=str(self.cache_dir)
#                     )
#                     self.model_name = model_name
#                 st.success(f"æ¨¡å‹ {model_name} è¼‰å…¥æˆåŠŸï¼")
#             return True
#         except Exception as e:
#             st.error(f"æ¨¡å‹è¼‰å…¥å¤±æ•—: {str(e)}")
#             return False

#     def validate_audio_file(self, file) -> bool:
#         """é©—è­‰éŸ³é »æª”æ¡ˆ"""
#         if file is None:
#             st.error("è«‹ä¸Šå‚³éŸ³é »æª”æ¡ˆ")
#             return False
        
#         max_size = 100 * 1024 * 1024  # 100MB
#         if file.size > max_size:
#             st.error("æª”æ¡ˆå¤§å°ä¸èƒ½è¶…é 100MB")
#             return False
            
#         return True

#     def process_audio(self, audio_file, progress_bar) -> Tuple[Optional[str], Optional[str]]:
#         """è™•ç†éŸ³é »æª”æ¡ˆä¸¦è¿”å›è½‰éŒ„çµæœ"""
#         if not self.validate_audio_file(audio_file):
#             return None, None

#         try:
#             with tempfile.NamedTemporaryFile(delete=False, suffix=Path(audio_file.name).suffix) as tmp_file:
#                 tmp_path = Path(tmp_file.name)
#                 # å¯«å…¥è‡¨æ™‚æª”æ¡ˆ
#                 progress_bar.progress(0.2, "æº–å‚™éŸ³é »æª”æ¡ˆ...")
#                 tmp_file.write(audio_file.getvalue())

#             try:
#                 # è½‰éŒ„è™•ç†
#                 progress_bar.progress(0.4, "é–‹å§‹è½‰éŒ„...")
#                 result = self.model.transcribe(
#                     str(tmp_path),
#                     language="zh",
#                     fp16=False,
#                     initial_prompt="ä»¥ç¹é«”ä¸­æ–‡è½‰éŒ„å…§å®¹"
#                 )
                
#                 progress_bar.progress(0.7, "ç”Ÿæˆè¼¸å‡º...")
                
#                 # ç”Ÿæˆæ–‡æœ¬è¼¸å‡º
#                 plain_text = self._generate_plain_text(result["segments"])
                
#                 # ç”Ÿæˆ SRT è¼¸å‡º
#                 srt_content = self._generate_srt(result["segments"])
                
#                 progress_bar.progress(1.0, "è™•ç†å®Œæˆï¼")
#                 return plain_text, srt_content
                
#             finally:
#                 # æ¸…ç†è‡¨æ™‚æª”æ¡ˆ
#                 if tmp_path.exists():
#                     tmp_path.unlink()
                    
#         except Exception as e:
#             st.error(f"è™•ç†å¤±æ•—: {str(e)}")
#             return None, None

#     def _generate_plain_text(self, segments) -> str:
#         """ç”Ÿæˆç´”æ–‡æœ¬è¼¸å‡º"""
#         return "\n".join([
#             segment['text'].strip() 
#             for segment in segments
#         ])

#     def _generate_srt(self, segments) -> str:
#         """ç”Ÿæˆ SRT æ ¼å¼è¼¸å‡º"""
#         srt_content = []
#         for i, segment in enumerate(segments, 1):
#             start_time = self._format_timestamp(segment['start'])
#             end_time = self._format_timestamp(segment['end'])
#             srt_content.append(
#                 f"{i}\n{start_time} --> {end_time}\n{segment['text'].strip()}\n"
#             )
#         return "\n".join(srt_content)

#     def _format_timestamp(self, seconds: float) -> str:
#         """æ ¼å¼åŒ–æ™‚é–“æˆ³"""
#         hours = int(seconds // 3600)
#         minutes = int((seconds % 3600) // 60)
#         seconds = int(seconds % 60)
#         milliseconds = int((seconds % 1) * 1000)
#         return f"{hours:02d}:{minutes:02d}:{seconds:02d},{milliseconds:03d}"

# def main():
#     st.set_page_config(
#         page_title="éŸ³é »è½‰æ–‡å­—å¹³å°",
#         page_icon="ğŸµ",
#         layout="wide"
#     )
    
#     st.title("ğŸµ éŸ³é »è½‰æ–‡å­—å¹³å°")
#     st.caption("æ”¯æ´ MP3ã€WAVã€M4Aã€FLAC æ ¼å¼éŸ³é »æª”æ¡ˆè½‰æ›ç‚ºæ–‡å­—å’Œå­—å¹•")
    
#     # åˆå§‹åŒ– session state
#     if 'converter' not in st.session_state:
#         st.session_state.converter = AudioConverter()
    
#     # å´é‚Šæ¬„è¨­ç½®
#     with st.sidebar:
#         st.subheader("âš™ï¸ è¨­ç½®")
#         selected_model = st.selectbox(
#             "é¸æ“‡æ¨¡å‹",
#             options=list(AudioConverter.SUPPORTED_MODELS.keys()),
#             format_func=lambda x: f"{x} - {AudioConverter.SUPPORTED_MODELS[x]}",
#             index=1  # é è¨­é¸æ“‡ base æ¨¡å‹
#         )
#         st.info(f"ç›®å‰ä½¿ç”¨çš„è¨­å‚™: {st.session_state.converter.device}")
    
#     # æª”æ¡ˆä¸Šå‚³å€åŸŸ
#     audio_file = st.file_uploader(
#         "ä¸Šå‚³éŸ³é »æª”æ¡ˆ",
#         type=["mp3", "wav", "m4a", "flac"],
#         help="æ”¯æ´çš„æ ¼å¼ï¼šMP3ã€WAVã€M4Aã€FLACï¼Œæª”æ¡ˆå¤§å°é™åˆ¶ï¼š100MB"
#     )
    
#     if audio_file:
#         st.audio(audio_file)
        
#         col1, col2 = st.columns([2, 1])
#         with col1:
#             process_button = st.button(
#                 "é–‹å§‹è™•ç†",
#                 type="primary",
#                 use_container_width=True
#             )
            
#         if process_button:
#             # è¼‰å…¥é¸æ“‡çš„æ¨¡å‹
#             if st.session_state.converter.load_model(selected_model):
#                 # é¡¯ç¤ºé€²åº¦æ¢
#                 progress_bar = st.progress(0, "æº–å‚™è™•ç†...")
                
#                 # è™•ç†éŸ³é »
#                 plain_text, srt_content = st.session_state.converter.process_audio(
#                     audio_file, progress_bar
#                 )
                
#                 if plain_text and srt_content:
#                     st.success("è™•ç†å®Œæˆï¼")
                    
#                     # é¡¯ç¤ºçµæœ
#                     col1, col2 = st.columns(2)
#                     with col1:
#                         st.subheader("ğŸ“ é€å­—ç¨¿")
#                         st.text_area(
#                             "ç´”æ–‡æœ¬è¼¸å‡º",
#                             plain_text,
#                             height=300
#                         )
#                         st.download_button(
#                             "ä¸‹è¼‰é€å­—ç¨¿ (TXT)",
#                             plain_text,
#                             f"{Path(audio_file.name).stem}_transcript.txt",
#                             mime="text/plain"
#                         )
                            
#                     with col2:
#                         st.subheader("ğŸ¬ å­—å¹•æª”")
#                         st.text_area(
#                             "SRT æ ¼å¼è¼¸å‡º",
#                             srt_content,
#                             height=300
#                         )
#                         st.download_button(
#                             "ä¸‹è¼‰å­—å¹•æª” (SRT)",
#                             srt_content,
#                             f"{Path(audio_file.name).stem}_subtitle.srt",
#                             mime="text/plain"
#                         )
#     else:
#         st.info("ğŸ‘† è«‹ä¸Šå‚³éŸ³é »æª”æ¡ˆé–‹å§‹è™•ç†")

# if __name__ == "__main__":
#     main()


import streamlit as st
import whisper
import torch
import warnings
from pathlib import Path
import tempfile
import logging
import os
from typing import Optional, Tuple

# è¨­ç½®ç’°å¢ƒè®Šæ•¸å’Œè­¦å‘Šæ§åˆ¶
os.environ["PYTHONWARNINGS"] = "ignore::FutureWarning"
os.environ["TORCH_ENABLE_CPU_FALLBACK"] = "1"
warnings.filterwarnings("ignore", category=FutureWarning)
warnings.filterwarnings("ignore", category=UserWarning)
logging.getLogger("whisper").setLevel(logging.ERROR)

class AudioConverter:
    # æ ¹æ“šåŸ·è¡Œç’°å¢ƒæ±ºå®šå¯ç”¨çš„æ¨¡å‹
    SUPPORTED_MODELS = {
        "tiny": "æœ€å°æ¨¡å‹ - æœ€å¿«ä½†æº–ç¢ºåº¦è¼ƒä½ (150MB)",
        "base": "åŸºç¤æ¨¡å‹ - å¹³è¡¡é€Ÿåº¦å’Œæº–ç¢ºåº¦ (290MB)",
        "small": "å°å‹æ¨¡å‹ - è¼ƒå¥½çš„æº–ç¢ºåº¦ (960MB)",
    }
    
    # æœ¬åœ°ç’°å¢ƒé¡å¤–æä¾›çš„æ¨¡å‹
    LOCAL_MODELS = {
        "medium": "ä¸­å‹æ¨¡å‹ - é«˜æº–ç¢ºåº¦ (1.5GB)",
        "large": "å¤§å‹æ¨¡å‹ - æœ€é«˜æº–ç¢ºåº¦ä½†è¼ƒæ…¢ (2.9GB)",
    }
    
    def __init__(self):
        """åˆå§‹åŒ–è½‰æ›å™¨"""
        self.model = None
        self.model_name = None
        # æª¢æŸ¥æ˜¯å¦åœ¨ Streamlit Cloud ç’°å¢ƒ
        self.is_cloud = self._is_streamlit_cloud()
        # æ ¹æ“šç’°å¢ƒé¸æ“‡è¨­å‚™
        self.device = self._get_device()
        # æ ¹æ“šç’°å¢ƒé¸æ“‡å¯ç”¨æ¨¡å‹
        self.available_models = self._get_available_models()
        
    def _is_streamlit_cloud(self) -> bool:
        """åˆ¤æ–·æ˜¯å¦åœ¨ Streamlit Cloud ç’°å¢ƒ"""
        return os.environ.get('STREAMLIT_CLOUD') == 'true'
    
    def _get_device(self) -> str:
        """æ ¹æ“šç’°å¢ƒé¸æ“‡é‹ç®—è¨­å‚™"""
        if self.is_cloud:
            return "cpu"
        return "cuda" if torch.cuda.is_available() else "cpu"
    
    def _get_available_models(self) -> dict:
        """æ ¹æ“šç’°å¢ƒè¿”å›å¯ç”¨çš„æ¨¡å‹åˆ—è¡¨"""
        if self.is_cloud:
            return self.SUPPORTED_MODELS
        return {**self.SUPPORTED_MODELS, **self.LOCAL_MODELS}
    
    @st.cache_resource(show_spinner=False)
    def load_model(_self, model_name: str):
        """
        ä½¿ç”¨ st.cache_resource ä¾†å¿«å–æ¨¡å‹
        é€™æ¨£åœ¨ Streamlit é‡æ–°é‹è¡Œæ™‚ä¸æœƒé‡è¤‡è¼‰å…¥æ¨¡å‹
        """
        return whisper.load_model(model_name, device=_self.device)

    def get_model(self, model_name: str) -> bool:
        """ç²å–æ¨¡å‹ï¼Œå¦‚æœå·²å¿«å–å‰‡ç›´æ¥è¿”å›"""
        try:
            if self.model_name != model_name:
                with st.spinner(f"è¼‰å…¥ {model_name} æ¨¡å‹ä¸­..."):
                    self.model = self.load_model(model_name)
                    self.model_name = model_name
                st.success(f"æ¨¡å‹ {model_name} è¼‰å…¥æˆåŠŸï¼")
            return True
        except Exception as e:
            st.error(f"æ¨¡å‹è¼‰å…¥å¤±æ•—: {str(e)}")
            return False

    def validate_audio_file(self, file) -> bool:
        """é©—è­‰éŸ³é »æª”æ¡ˆ"""
        if file is None:
            st.error("è«‹ä¸Šå‚³éŸ³é »æª”æ¡ˆ")
            return False
        
        # æ ¹æ“šç’°å¢ƒè¨­ç½®å¤§å°é™åˆ¶
        max_size = 50 * 1024 * 1024 if self.is_cloud else 100 * 1024 * 1024
        if file.size > max_size:
            st.error(f"æª”æ¡ˆå¤§å°ä¸èƒ½è¶…é {'50MB' if self.is_cloud else '100MB'}")
            return False
            
        return True

    def process_audio(self, audio_file, progress_bar) -> Tuple[Optional[str], Optional[str]]:
        """è™•ç†éŸ³é »æª”æ¡ˆä¸¦è¿”å›è½‰éŒ„çµæœ"""
        if not self.validate_audio_file(audio_file):
            return None, None

        temp_dir = None
        temp_path = None
        
        try:
            # å‰µå»ºè‡¨æ™‚ç›®éŒ„
            temp_dir = tempfile.mkdtemp()
            # åœ¨è‡¨æ™‚ç›®éŒ„ä¸­å‰µå»ºæª”æ¡ˆ
            temp_path = Path(temp_dir) / f"audio{Path(audio_file.name).suffix}"
            
            progress_bar.progress(0.2, "æº–å‚™éŸ³é »æª”æ¡ˆ...")
            # å¯«å…¥éŸ³é »æ•¸æ“š
            with open(temp_path, 'wb') as f:
                f.write(audio_file.getvalue())
            
            # ç¢ºä¿æª”æ¡ˆå¯«å…¥å®Œæˆ
            progress_bar.progress(0.4, "é–‹å§‹è½‰éŒ„...")
            
            # è½‰éŒ„è™•ç†
            result = self.model.transcribe(
                str(temp_path),
                language="zh",
                fp16=torch.cuda.is_available() and not self.is_cloud,  # åœ¨æœ¬åœ° GPU ç’°å¢ƒå•Ÿç”¨ fp16
                initial_prompt="ä»¥ç¹é«”ä¸­æ–‡è½‰éŒ„å…§å®¹"
            )
            
            progress_bar.progress(0.7, "ç”Ÿæˆè¼¸å‡º...")
            
            # ç”Ÿæˆè¼¸å‡º
            plain_text = self._generate_plain_text(result["segments"])
            srt_content = self._generate_srt(result["segments"])
            
            progress_bar.progress(1.0, "è™•ç†å®Œæˆï¼")
            return plain_text, srt_content
                    
        except Exception as e:
            st.error(f"è™•ç†å¤±æ•—: {str(e)}")
            return None, None
            
        finally:
            # æ¸…ç†è‡¨æ™‚æª”æ¡ˆ
            try:
                if temp_path and temp_path.exists():
                    temp_path.unlink()
                if temp_dir and Path(temp_dir).exists():
                    Path(temp_dir).rmdir()
            except Exception as e:
                print(f"æ¸…ç†è‡¨æ™‚æª”æ¡ˆæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")

    def _generate_plain_text(self, segments) -> str:
        """ç”Ÿæˆç´”æ–‡æœ¬è¼¸å‡º"""
        return "\n".join([
            segment['text'].strip() 
            for segment in segments
        ])

    def _generate_srt(self, segments) -> str:
        """ç”Ÿæˆ SRT æ ¼å¼è¼¸å‡º"""
        srt_content = []
        for i, segment in enumerate(segments, 1):
            start_time = self._format_timestamp(segment['start'])
            end_time = self._format_timestamp(segment['end'])
            srt_content.append(
                f"{i}\n{start_time} --> {end_time}\n{segment['text'].strip()}\n"
            )
        return "\n".join(srt_content)

    def _format_timestamp(self, seconds: float) -> str:
        """æ ¼å¼åŒ–æ™‚é–“æˆ³"""
        hours = int(seconds // 3600)
        minutes = int((seconds % 3600) // 60)
        seconds = int(seconds % 60)
        milliseconds = int((seconds % 1) * 1000)
        return f"{hours:02d}:{minutes:02d}:{seconds:02d},{milliseconds:03d}"

def main():
    st.set_page_config(
        page_title="èªéŸ³è½‰æ–‡å­—å¹³å°",
        page_icon="ğŸµ",
        layout="wide"
    )
    
    st.title("ğŸµ èªéŸ³è½‰æ–‡å­—")
    st.caption("æ”¯æ´ MP3ã€WAVã€M4Aã€FLAC æ ¼å¼éŸ³é »æª”æ¡ˆè½‰æ›ç‚ºæ–‡å­—å’Œå­—å¹•")
    
    # åˆå§‹åŒ– session state
    if 'converter' not in st.session_state:
        st.session_state.converter = AudioConverter()
    
    # å´é‚Šæ¬„è¨­ç½®
    with st.sidebar:
        st.subheader("âš™ï¸ è¨­ç½®")
        
        # é¡¯ç¤ºé‹è¡Œç’°å¢ƒè³‡è¨Š
        env_info = "ğŸ–¥ï¸ æœ¬åœ°ç’°å¢ƒ" if not st.session_state.converter.is_cloud else "â˜ï¸ é›²ç«¯ç’°å¢ƒ"
        device_info = f"ä½¿ç”¨ {'GPU' if st.session_state.converter.device == 'cuda' else 'CPU'} é‹ç®—"
        st.info(f"{env_info} - {device_info}")
        
        selected_model = st.selectbox(
            "é¸æ“‡æ¨¡å‹",
            options=list(st.session_state.converter.available_models.keys()),
            format_func=lambda x: f"{x} - {st.session_state.converter.available_models[x]}",
            index=1  # é è¨­é¸æ“‡ base æ¨¡å‹
        )
        
        st.markdown(f"""
        ### ğŸ“ ä½¿ç”¨èªªæ˜
        1. é¸æ“‡åˆé©çš„æ¨¡å‹
        2. ä¸Šå‚³éŸ³é »æª”æ¡ˆï¼ˆé™åˆ¶ {'50MB' if st.session_state.converter.is_cloud else '100MB'} ä»¥ä¸‹ï¼‰
        3. é»æ“Šè™•ç†æŒ‰éˆ•é–‹å§‹è½‰æ›
        4. ä¸‹è¼‰è½‰æ›çµæœ
        
        ### â„¹ï¸ æ¨¡å‹èªªæ˜
        - tiny: é©åˆç°¡çŸ­ã€æ¸…æ™°çš„éŸ³é »
        - base: ä¸€èˆ¬ç”¨é€”ï¼Œé©åˆå¤§å¤šæ•¸å ´æ™¯
        - small: è¼ƒé«˜æº–ç¢ºåº¦ï¼Œä½†è™•ç†è¼ƒæ…¢
        {'- medium: é«˜æº–ç¢ºåº¦ï¼Œé©åˆè¼ƒé•·éŸ³é »' if not st.session_state.converter.is_cloud else ''}
        {'- large: æœ€é«˜æº–ç¢ºåº¦ï¼Œé©åˆè¤‡é›œéŸ³é »' if not st.session_state.converter.is_cloud else ''}
        """)
    
    # æª”æ¡ˆä¸Šå‚³å€åŸŸ
    audio_file = st.file_uploader(
        "ä¸Šå‚³éŸ³é »æª”æ¡ˆ",
        type=["mp3", "wav", "m4a", "flac"],
        help=f"æ”¯æ´çš„æ ¼å¼ï¼šMP3ã€WAVã€M4Aã€FLACï¼Œæª”æ¡ˆå¤§å°é™åˆ¶ï¼š{'50MB' if st.session_state.converter.is_cloud else '100MB'}"
    )
    
    if audio_file:
        st.audio(audio_file)
        
        col1, col2 = st.columns([2, 1])
        with col1:
            process_button = st.button(
                "é–‹å§‹è™•ç†",
                type="primary",
                use_container_width=True
            )
            
        if process_button:
            # è¼‰å…¥é¸æ“‡çš„æ¨¡å‹
            if st.session_state.converter.get_model(selected_model):
                # é¡¯ç¤ºé€²åº¦æ¢
                progress_bar = st.progress(0, "æº–å‚™è™•ç†...")
                
                # è™•ç†éŸ³é »
                plain_text, srt_content = st.session_state.converter.process_audio(
                    audio_file, progress_bar
                )
                
                if plain_text and srt_content:
                    st.success("è™•ç†å®Œæˆï¼")
                    
                    # é¡¯ç¤ºçµæœ
                    col1, col2 = st.columns(2)
                    with col1:
                        st.subheader("ğŸ“ é€å­—ç¨¿")
                        st.text_area(
                            "ç´”æ–‡æœ¬è¼¸å‡º",
                            plain_text,
                            height=300
                        )
                        st.download_button(
                            "ä¸‹è¼‰é€å­—ç¨¿ (TXT)",
                            plain_text,
                            f"{Path(audio_file.name).stem}_transcript.txt",
                            mime="text/plain"
                        )
                            
                    with col2:
                        st.subheader("ğŸ¬ å­—å¹•æª”")
                        st.text_area(
                            "SRT æ ¼å¼è¼¸å‡º",
                            srt_content,
                            height=300
                        )
                        st.download_button(
                            "ä¸‹è¼‰å­—å¹•æª” (SRT)",
                            srt_content,
                            f"{Path(audio_file.name).stem}_subtitle.srt",
                            mime="text/plain"
                        )
    else:
        st.info("ğŸ‘† è«‹ä¸Šå‚³éŸ³é »æª”æ¡ˆé–‹å§‹è™•ç†")

if __name__ == "__main__":
    main()